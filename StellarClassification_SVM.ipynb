{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95808ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"/content/drive/MyDrive/star_classification.csv\", sep=',')\n",
    "output = data['class']\n",
    "input = data.drop(['class','rerun_ID'], axis=1)\n",
    "\n",
    "input_max = input.max()\n",
    "input_min = input.min()\n",
    "input_normalized = (input - input_min) / (input_max - input_min)\n",
    "df = pd.DataFrame(input_normalized)\n",
    "\n",
    "# # Compute the correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# # Visualize the correlation matrix using a heatmap\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.show()\n",
    "dataset = pd.concat([input_normalized, output], axis=1)\n",
    "\n",
    "# Shuffle the dataset (by shuffling rows)\n",
    "shuffled_dataset = dataset.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Calculate the index to split the dataset (90% for training and 10% for testing)\n",
    "train_size = int(0.9 * len(shuffled_dataset))\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_data = shuffled_dataset[:train_size]\n",
    "test_data = shuffled_dataset[train_size:]\n",
    "\n",
    "# Separate features and labels for training and testing\n",
    "input_normalized = train_data.drop('class', axis=1)\n",
    "output = train_data['class']\n",
    "\n",
    "X_test = test_data.drop('class', axis=1)\n",
    "Y_test = test_data['class']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot histogram of the classes\n",
    "output.value_counts().plot(kind='bar', color='skyblue')\n",
    "plt.title('Class Distribution Before Oversampling Minority Cases')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Check class distribution\n",
    "class_counts = output.value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "max_class_size = class_counts.max()\n",
    "classes = class_counts.index\n",
    "\n",
    "print(f\"Majority Class Size: {max_class_size}\")\n",
    "\n",
    "# oversample\n",
    "oversampled_data = []\n",
    "# Loop through each class\n",
    "for cls in classes:\n",
    "    class_data = input_normalized[output == cls]  # Get data for the current class\n",
    "    oversampled_class = class_data.sample(max_class_size, replace=True, random_state=42)  # Oversample with replacement\n",
    "    oversampled_data.append(oversampled_class)\n",
    "\n",
    "# Combine all oversampled classes\n",
    "oversampled_input = pd.concat(oversampled_data, axis=0)\n",
    "\n",
    "# Create the corresponding labels\n",
    "oversampled_output = pd.Series(\n",
    "    [cls for cls in classes for _ in range(max_class_size)],\n",
    "    name='class'\n",
    ")\n",
    "\n",
    "\n",
    "#shuffle\n",
    "# Reset indices of oversampled data and labels\n",
    "oversampled_input = oversampled_input.reset_index(drop=True)\n",
    "oversampled_output = oversampled_output.reset_index(drop=True)\n",
    "\n",
    "# Combine input and output\n",
    "balanced_data = pd.concat([oversampled_input, oversampled_output], axis=1)\n",
    "\n",
    "# Shuffle the dataset\n",
    "balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "input = data.drop(['class'], axis=1)\n",
    "\n",
    "data = balanced_data\n",
    "\n",
    "output = data['class']\n",
    "\n",
    "input = data.drop(['class'], axis=1)\n",
    "\n",
    "\n",
    "input_max = input.max()\n",
    "\n",
    "input_min = input.min()\n",
    "\n",
    "input_normalized = (input - input_min) / (input_max - input_min)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "balanced_data['class'].value_counts().plot(kind='bar', color='lightblue', edgecolor='black')\n",
    "plt.title('Class Distribution After Oversampling')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffb7438",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def one_hot_representation(class_array):\n",
    "    data = list(set(class_array))\n",
    "    num_classes = len(data)\n",
    "    one_hot = np.eye(num_classes)\n",
    "    one_hot_encoded = np.array([one_hot[:,data.index(label)] for label in class_array])\n",
    "\n",
    "    # one=np.where(class_array == data[0], one_hot[:,2] , 0)\n",
    "    label = np.split(one_hot,one_hot.shape[1],axis=0)\n",
    "\n",
    "    return one_hot_encoded , label\n",
    "\n",
    "def loss(y_true, y_pred):\n",
    "\n",
    "    epsilon = 1e-9  # Small value to prevent log(0)\n",
    "    # Clip y_pred to avoid log(0)\n",
    "    y_pred = np.clip(y_pred, epsilon, 1. - epsilon)\n",
    "\n",
    "    # Compute cross-entropy loss\n",
    "\n",
    "    # print(y_pred)\n",
    "    loss = -np.sum(y_true * np.log(y_pred)) / y_true.shape[0]\n",
    "    return loss\n",
    "def softmax(z):\n",
    "    # Subtracting the max of z for numerical stability\n",
    "    # This prevents overflow by scaling the logits\n",
    "\n",
    "    z_exp = np.exp(z - np.max(z, axis=1, keepdims=True))  # Exponentiate the logits (with stability adjustment)\n",
    "    # print(z - np.max(z, axis=1, keepdims=True))\n",
    "    # print(np.sum(z_exp, axis=1, keepdims=True))\n",
    "    return z_exp / np.sum(z_exp, axis=0, keepdims=True)  # Normalize the values to sum to 1\n",
    "def accuracy_score(y_test, y_pred):\n",
    "    # Check if the lengths of y_test and y_pred are the same\n",
    "    if len(y_test) != len(y_pred):\n",
    "        raise ValueError(\"The length of y_test and y_pred must be the same.\")\n",
    "    y_test_class = np.argmax(y_test, axis=1)\n",
    "    y_pred_class = np.argmax(y_pred, axis=1)\n",
    "    # Count the number of correct predictions (where y_test[i] == y_pred[i])\n",
    "    correct_predictions = np.sum(y_test_class == y_pred_class)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_predictions / len(y_test)\n",
    "\n",
    "    return accuracy\n",
    "def f1(y_test, y_pred, class_labels):\n",
    "    # Initialize F1 scores list for each class\n",
    "    f1_scores = []\n",
    "\n",
    "    # For each class label\n",
    "    for label in class_labels:\n",
    "        # True Positives (TP): Correct predictions of the current class\n",
    "        TP = np.sum((y_test == label) & (y_pred == label))\n",
    "        # False Positives (FP): Incorrect predictions of the current class (predicted as 'label' but actually not 'label')\n",
    "        FP = np.sum((y_test != label) & (y_pred == label))\n",
    "        # False Negatives (FN): Instances of the current class that were misclassified\n",
    "        FN = np.sum((y_test == label) & (y_pred != label))\n",
    "\n",
    "        # Precision and Recall\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "        # F1 Score for this class\n",
    "        f1_class = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        f1_scores.append(f1_class)\n",
    "\n",
    "    # Return the average F1 score (macro average in this case)\n",
    "    return np.mean(f1_scores)\n",
    "class MultiClassSVM:\n",
    "    def _init_(self, classes = 3, regularization = 0, epoch = 5, learning_rate = 0.001, kernel=\"linear\"):\n",
    "        self.classifiers = {}\n",
    "        self.class_indices = {}  # Map class tuples to integer indices\n",
    "        self.num_classes = classes\n",
    "        self.regularization = regularization\n",
    "        self.epoch = epoch\n",
    "        self.lr = learning_rate\n",
    "        self.kernel = kernel\n",
    "    def fit(self, X, Y):\n",
    "\n",
    "        unique_classes = np.unique(Y, axis=0)\n",
    "\n",
    "        for i in range(len(unique_classes)):\n",
    "            for j in range(i + 1, len(unique_classes)):\n",
    "\n",
    "                relevant_indices = (Y == unique_classes[i]) | (Y == unique_classes[j])\n",
    "\n",
    "                relevant = np.where(np.all(relevant_indices, axis=1))\n",
    "\n",
    "                input = X[relevant[0]]\n",
    "                output = Y[relevant[0]]\n",
    "\n",
    "                binary_labels = np.where(np.all(output == unique_classes[i], axis=1), -1, 1)\n",
    "\n",
    "                model = SVM(learning_rate=self.lr, epoch= self.epoch, num_classes=self.num_classes, regularization=self.regularization, kernel = self.kernel)\n",
    "\n",
    "\n",
    "                model.fit(input, binary_labels)\n",
    "\n",
    "                class_tuple = (tuple(unique_classes[i]), tuple(unique_classes[j]))\n",
    "                self.classifiers[class_tuple] = model\n",
    "\n",
    "                # Create mapping for class tuple to index\n",
    "                if class_tuple not in self.class_indices:\n",
    "                    self.class_indices[class_tuple] = (i, j)\n",
    "\n",
    "    def predict(self, data):\n",
    "        # Determine the number of classes\n",
    "        #num_classes = len(self.classifiers) + 1  # Assuming one vs. one classification\n",
    "\n",
    "        # Initialize votes array with dimensions (num_samples, num_classes)\n",
    "        votes = np.zeros((len(data), self.num_classes))\n",
    "        class_dict = {}\n",
    "\n",
    "        for (class1, class2), classifier in self.classifiers.items():\n",
    "\n",
    "\n",
    "            # Get predictions for the binary classifier\n",
    "            predictions = classifier.predict(data)\n",
    "\n",
    "            # Map binary predictions (-1, 1) to votes for respective classes\n",
    "            class1_index, class2_index = self.class_indices[(class1, class2)]\n",
    "\n",
    "\n",
    "\n",
    "            class_dict[str(class1_index)] = class1\n",
    "            class_dict[str(class2_index)] = class2\n",
    "            votes[:, class1_index] += np.where(predictions == -1, 1, 0).flatten()  # Votes for class1\n",
    "            votes[:, class2_index] += np.where(predictions == 1, 1, 0).flatten()   # Votes for class2\n",
    "\n",
    "        # Determine the class with the highest votes for each sample\n",
    "\n",
    "        pred_indices = np.argmax(votes, axis=1)\n",
    "        predictions = []\n",
    "        for i in range(len(pred_indices)):\n",
    "\n",
    "            z = class_dict[str(pred_indices[i])]\n",
    "\n",
    "            predictions.append(z)\n",
    "\n",
    "\n",
    "        return predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SVM:\n",
    "    def __init__(self, learning_rate=0.001, epoch=10, num_classes=3, kernel = \"linear\", regularization=0, gamma = 0, degree = 2, coef0 = 1):\n",
    "        self.lr = learning_rate\n",
    "        self.epoch = epoch\n",
    "        self.classes = num_classes\n",
    "        self.parameters={}\n",
    "        self.losses = {}\n",
    "        self.kernel = kernel\n",
    "        self.regularization = regularization\n",
    "        self.gamma = gamma\n",
    "        self.degree = degree\n",
    "        self.coef0 = coef0\n",
    "    def kernel_function(self, X, X2=None):\n",
    "        if self.kernel == 'linear':\n",
    "            return X\n",
    "        elif self.kernel == 'rbf':\n",
    "    \n",
    "            sq_dists = np.sum(X*2, axis=1).reshape(-1, 1) + np.sum(X2*2, axis=1) - 2 * np.dot(X, X2.T)\n",
    "            return np.exp(-self.gamma * sq_dists)\n",
    "        elif self.kernel == 'polynomial':\n",
    "            return (np.dot(X, X2.T) + self.coef0) ** self.degree\n",
    "        else:\n",
    "            raise ValueError(\"Kernel not supported\")\n",
    "\n",
    "    def forward_pass(self, X):\n",
    "        # Use the kernel function to calculate the decision function\n",
    "        K = self.kernel_function(X)\n",
    "        z = np.dot(K, self.parameters[\"W\"]) + self.parameters[\"b\"]\n",
    "        A = softmax(z)\n",
    "        return A\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        # Call kernel function\n",
    "\n",
    "        X = self.kernel_function(X,X)\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "\n",
    "        # init parameters\n",
    "        # for i in range(n_features):\n",
    "\n",
    "        self.parameters[\"W\"] = np.random.randn(n_features,1) * 0.01  # Weight matrix\n",
    "        self.parameters[\"b\"] = np.zeros((1,1))  # Bias vector\n",
    "\n",
    "        # gradient descent\n",
    "        for _ in range(self.epoch):\n",
    "            for j in range(n_samples):\n",
    "\n",
    "                A = X[j].reshape(n_features,1)\n",
    "\n",
    "                prediction =(np.dot(A.T, self.parameters[\"W\"]) + self.parameters[\"b\"])\n",
    "\n",
    "                margin = y[j]* prediction\n",
    "                # print((np.dot(X[j]., self.parameters[\"W\"])).shape)\n",
    "                if margin >= 1:\n",
    "                    dw = 2 * self.regularization * self.parameters[\"W\"]\n",
    "                    db = 0\n",
    "                else:\n",
    "                    dw = 2 * self.regularization * self.parameters[\"W\"] - y[j] * A\n",
    "                    db = y[j]\n",
    "                self.parameters[\"W\"] = self.parameters[\"W\"] - self.lr * dw\n",
    "                self.parameters[\"b\"] = self.parameters[\"b\"] - self.lr * db\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "\n",
    "        X = self.kernel_function(X,X)\n",
    "        y_hat = np.dot(X, self.parameters[\"W\"]) + self.parameters[\"b\"]\n",
    "        A = np.sign(y_hat)\n",
    "\n",
    "        return A\n",
    "        \n",
    "def compute_confusion_matrix(y_test , y_pred):\n",
    "\n",
    "    Y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    Y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Create a confusion matrix\n",
    "    conf_matrix = confusion_matrix(Y_test_classes, Y_pred_classes)\n",
    "\n",
    "# Display the confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=[\"Galaxy\", \"Star\", \"QSO\"])\n",
    "    disp.plot(cmap=\"Blues\")\n",
    "    plt.title(\"Confusion Matrix for SVM\")\n",
    "    plt.show()\n",
    "\n",
    "    return conf_matrix\n",
    "def k_fold(X, Y, k=5, shuffle=False,learning = 0.001,epoch = 1000, regularization = 0):\n",
    "    # Step 1: Shuffle the data\n",
    "    if shuffle:\n",
    "        indices = np.random.permutation(len(X))\n",
    "\n",
    "        X_shuffled = X.iloc[indices]\n",
    "        Y_shuffled = Y.iloc[indices]\n",
    "\n",
    "\n",
    "    else:\n",
    "        X_shuffled = X\n",
    "        Y_shuffled = Y\n",
    "    Y_shuffled_ohr, oh_labels = one_hot_representation(Y_shuffled) # One hot representation of classes\n",
    "\n",
    "    # Step 2: Split data into k folds\n",
    "    fold_size = len(X) // k\n",
    "    accuracies = []  # List to store accuracy for each fold\n",
    "    f1_scores = []\n",
    "    cm = []\n",
    "    for i in range(k):\n",
    "    # Step 3: Define the test set for this fold\n",
    "        test_start = i * fold_size\n",
    "        test_end = (i + 1) * fold_size if i != k - 1 else len(X)\n",
    "\n",
    "    # Split data into training and test sets\n",
    "        X_train = np.concatenate([X_shuffled[:test_start], X_shuffled[test_end:]], axis=0)\n",
    "        Y_train = np.concatenate([Y_shuffled_ohr[:test_start], Y_shuffled_ohr[test_end:]], axis=0)\n",
    "        X_valid = X_shuffled[test_start:test_end]\n",
    "        Y_valid = Y_shuffled_ohr[test_start:test_end]\n",
    "\n",
    "\n",
    "        # Step 4: Train the model on the training set\n",
    "        model = MultiClassSVM(classes = len(oh_labels),regularization= regularization, epoch=epoch,)\n",
    "        # model(learning , iterations , num_class)\n",
    "        model.fit(X_train, Y_train)\n",
    "\n",
    "        # Step 5: Make predictions on the test set\n",
    "        Y_pred = model.predict(X_valid)\n",
    "\n",
    "        # Step 6: Calculate accuracy for this fold\n",
    "        accuracy = accuracy_score(Y_valid, Y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        f1_score = f1(Y_valid, Y_pred, oh_labels)\n",
    "        f1_scores.append(f1_score)\n",
    "    # Step 7: Calculate the average accuracy across all folds\n",
    "    average_accuracy = np.mean(accuracies)\n",
    "    average_f1_score = np.mean(f1_scores)\n",
    "    print(\"For SVM: \")\n",
    "    print(\"For learning rate \" + str(learning) + \" and epoch \" + str(epoch)  + \" and regularization \" + str(regularization) )\n",
    "    print(\"Validation Accuracy: \" + str(average_accuracy))\n",
    "    print(\"Validation F1 Score: \" + str(average_f1_score) + \"\\n\")\n",
    "    return accuracies, average_accuracy, f1_scores, average_f1_score,model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b97fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_ohr, oh_lab = one_hot_representation(Y_test)\n",
    "\n",
    "Acc, Av_acc, F1, Av_f1, model = k_fold(input_normalized, output,k=5, shuffle=True,learning = 0.001 ,epoch=70,regularization = 0)\n",
    "print(\"Validation Accuracies are \" + str(Acc))\n",
    "print(\"Validation F1 Scores are \" + str(F1))\n",
    "\n",
    "best = np.argmax(F1)\n",
    "best_model = model[best]\n",
    "\n",
    "predictions = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(Y_test_ohr, predictions)\n",
    "f1_score = f1(Y_test_ohr, predictions, oh_lab)\n",
    "cm = (compute_confusion_matrix(Y_test_ohr, predictions))\n",
    "print(\"Test Accuracy: \" + str(accuracy))\n",
    "print(\"Test F1 Score: \" + str(f1_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
